{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Membership Inference Attacks Against Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elements of the adversarial system:\n",
    "* Shadow model\n",
    "* Attack model\n",
    "\n",
    "###  Shadow Model\n",
    "\n",
    "The adversary trains $k$ shadow models, each on a dataset (shadow data) that is similar\n",
    "in format and distribution as the __target model's private training set__.\n",
    "\n",
    "Generate shadow data drawing samples from the population where the target model's training data\n",
    "are drawn from. The shadow model must be __trained in a similar fashion as the target model__.\n",
    "The larger the number of shadow models, the better the accuracy of the attack model.\n",
    "\n",
    "### Attack Model\n",
    "\n",
    "The adversary queries each shadow model with its own disjoint training and test dataset which are of the __same size__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating training data for shadow models\n",
    "\n",
    "The adversary needs training data that is distributed similarly to the target model's training data. \n",
    "Shoki's proposed methods are:\n",
    "\n",
    "### Model-based synthesis:\n",
    "Attacker does not have real raining data nor any statistics abouts its distribution.\n",
    "Generate synthetic data for the shadow model using the target model itself. The intuition is that records that are classified by the target model \n",
    "with high confidence should be statistically similar to the target's training training dataset.\n",
    "\n",
    "Two phases of synthesis process:\n",
    "1. _Search_ using a hill-climbing algorithm the space of possible data records to find inputs that are classified by the target model with high confidence.\n",
    "2. _Sample_ synthetic data from records. After synthetised a record, repeat until shadow dataset is full\n",
    "\n",
    ">>\n",
    "First fix class $c$ for which attacker wants to generate synthetic data.\n",
    "Initialize randomly a data record $\\mathbf{x}$.\n",
    "The attacker must known the syntactic format of data records (number of features and numerical range of each feature).\n",
    "Sample the value for each feature uniformly at random from among all possible values of that feature.\n",
    ">>\n",
    "A proposed record is _accepted_ only if it increases the [hill-climbing](https://en.wikipedia.org/wiki/Hill_climbing) objective: the probability of\n",
    "being classified by the target model as class $c$.\n",
    ">>\n",
    "Each iteration involves proposing a new candidate record by changing $k$ randomly selected features of the latest accepted record $\\mathbf{x^∗}$.\n",
    "This is done by flipping binary features or resampling new values for features of other types.\n",
    "We initialize $k$ to $k_{max}$ and divide it by 2 when $rej_{max}$ subsequent proposals are rejected. This controls the diameter of search around the\n",
    "accepted record in order to propose a new record. We set the\n",
    "minimum value of $k$ to $k_{min}$.\n",
    "This controls the speed of the search for new records with a potentially higher classification\n",
    "probability $y_c$.\n",
    ">>\n",
    "The second, sampling phase starts when the target model’s\n",
    "probability $y_c$ that the proposed data record is classified as belonging to class $c$ is larger than the probabilities for all\n",
    "other classes and also larger than a threshold $conf_{min}$.\n",
    "This ensures that the predicted label for the record is $c$, and that the target model is sufficiently confident in its label prediction. We\n",
    "select such record for the synthetic dataset with probability $y_{c}^∗$\n",
    "and, if selection fails, repeat until a record is selected.\n",
    ">>\n",
    "This synthesis procedure works only if the adversary can\n",
    "efficiently explore the space of possible inputs and discover\n",
    "inputs that are classified by the target model with high confi-\n",
    "dence. For example, it may not work if the inputs are high-\n",
    "resolution images and the target model performs a complex\n",
    "image classification task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of the data synthesis algorithm proposet by Shokri et al.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def features_generator(n_features: int,\n",
    "                       types: str,\n",
    "                       rang: tuple=(0,1)) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Creates a n features vector with uniform features\n",
    "    sampled from a given range.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_features: int\n",
    "        number of features or length of the vector\n",
    "    \n",
    "    types: str\n",
    "        type of the features. It only accepts uniform types.\n",
    "    \n",
    "    rang: tuple(int, int)\n",
    "        range of the random uniform population from \n",
    "        where to drawn samples\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    x: np.ndarray\n",
    "        features vector\n",
    "    \"\"\"\n",
    "    if types not in ('binary', 'int', 'float'):\n",
    "        raise ValueError(\"Parameter `types` must be 'binary', 'int' or 'float'\")\n",
    "    if types == 'binary':\n",
    "        x = np.random.randint(0, 2, n_features)\n",
    "    if types == 'int':\n",
    "        x = np.random.randint(rang[0], rang[1], n_features)\n",
    "    if types == 'float':\n",
    "        x = np.random.uniform(rang[0], rang[1], n_features)\n",
    "    return x\n",
    "\n",
    "\n",
    "def feature_randomizer(x: np.ndarray, k: int, types: str, rang: tuple) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Randomizes k features from feature vector x\n",
    "    \"\"\"\n",
    "    idx_to_change = np.random.randint(0, len(x), size=k)\n",
    "    \n",
    "    new_feats = features_generator(k, types, rang)\n",
    "    \n",
    "    x[idx_to_change] = new_feats\n",
    "    return x\n",
    "\n",
    "\n",
    "def synthesize(class_: int,\n",
    "               n_features: int,\n",
    "               target_model,\n",
    "               k_max: int):\n",
    "    \"\"\"\n",
    "    Generates synthetic records that are classified\n",
    "    by the target model with high confidence.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    class_: int\n",
    "        fixed class which attacker wants to drawn samples from\n",
    "    \n",
    "    n_features: int\n",
    "        number of features per input vector\n",
    "    \n",
    "    target_model: estimator\n",
    "        Estimator that returns a class probability vector\n",
    "        from an input features vector. Implemented for\n",
    "        sklearn.base.BaseEstimator with `predict_proba()`\n",
    "        method.\n",
    "    \n",
    "    k_max: int\n",
    "        max \"radius\" of feature perturbation\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    x: np.ndarray\n",
    "        synthetic feature vector\n",
    "    \"\"\"\n",
    "    x = features_generator(n_features, types='float') # random record\n",
    "    y_c_current = 0  # target model’s probability of fixed class\n",
    "    j = 0  # consecutives rejections counter\n",
    "    k = k_max\n",
    "    k_min = 3\n",
    "    max_iter = 1000\n",
    "    conf_min = 0.8  # min prob cutoff to consider a record member of the class\n",
    "    rej_max = 10  # max number of consecutive rejections\n",
    "    for i in range(max_iter):\n",
    "        y = target_model.predict_proba(x)  # query target model\n",
    "        y_c = y[class_]\n",
    "        if y_c >= y_c_current:\n",
    "            if (y_c > conf_min)  and (class_ == np.argmax(y)):\n",
    "                if rand(WTF) < y_c:\n",
    "                    return x\n",
    "            x_new = x\n",
    "            y_c_current = y_c\n",
    "            j = 0\n",
    "        else:\n",
    "            j += 1\n",
    "            if j > rej_max: \n",
    "                k = max(k_min, np.ceil(k/2))\n",
    "                j = 0\n",
    "            \n",
    "        x = feature_randomizer(x_new, k)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics-based synthesis\n",
    "\n",
    ">>\n",
    "The attacker may have some statistical information about the population from which the target\n",
    "model’s training data was drawn.\n",
    "For example, the attacker may have prior knowledge of the marginal distributions of different features.\n",
    "In our experiments, we generate synthetic training records for the shadow models by independently\n",
    "sampling the value of each feature from its own marginal distribution.\n",
    "The resulting attack models are very effective."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
